{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     del FurnitureArray2 ,env ,wallsArray2,offsetZ,offsetX,Keywords\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "[Object(id='9C041969-296E-465A-804A-1BACEA6CBAD2', confidence='medium', transform=[-0.8415238261222839, 0.0, -0.5402198433876038, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5402198433876038, 0.0, -0.8415238261222839, 0.0, -0.5, -0.783364474773407, 0.92, 1.0], category='chair', scale=ObjectScale(x=0.4791486859321594, y=0.8396413326263428, z=0.47688254714012146)), Object(id='E14DACCD-452C-45CF-A62E-58FEE95F2B74', confidence='medium', transform=[-0.7236955165863037, 0.0, -0.6901194453239441, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6901194453239441, 0.0, -0.7236954569816589, 0.0, -1.01, -0.8804208636283875, 3.26, 1.0], category='bed', scale=ObjectScale(x=1.2986377477645874, y=0.6455289125442505, z=1.9645928144454956)), Object(id='4111C90B-6500-4778-AC02-7E9AD9C47361', confidence='medium', transform=[-0.6901196241378784, 0.0, 0.7236952781677246, 0.0, 0.0, 0.9999999403953552, 0.0, 0.0, -0.7236952185630798, 0.0, -0.6901195645332336, 0.0, 0.84, -0.03163617104291916, 1.52, 1.0], category='storage', scale=ObjectScale(x=2.0792393684387207, y=2.3430981636047363, z=0.5733171105384827)), Object(id='DD734DCA-4594-40AB-9BF9-A7CE4C0AA208', confidence='medium', transform=[-0.7236952185630798, 0.0, -0.6901195049285889, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6901195049285889, 0.0, -0.7236952185630798, 0.0, 0.76, -0.9261075854301453, 2.51, 1.0], category='bed', scale=ObjectScale(x=1.3680981397628784, y=0.5541555881500244, z=1.9604029655456543)), Object(id='5DE92784-7A70-454B-A340-0CE71C39B297', confidence='medium', transform=[-0.7236956357955933, 0.0, -0.6901190876960754, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6901190876960754, 0.0, -0.7236956357955933, 0.0, -1.19, -0.9458100199699402, 1.52, 1.0], category='storage', scale=ObjectScale(x=0.5578836798667908, y=0.5147507190704346, z=0.4564693868160248))]\n",
      "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
      "[<rect(303, 175, 277, 265)>, <rect(124, 8, 247, 259)>, <rect(513, 21, 238, 249)>, <rect(302, -145, 224, 213)>, <rect(611, -16, 54, 51)>, <rect(605, 7, 9, 10)>, <rect(258, 270, 60, 63)>, <rect(633, 137, 73, 76)>]\n",
      "[<rect(483, 134, 64, 64)>, <rect(242, -186, 228, 230)>, <rect(258, 98, 184, 189)>, <rect(162, -13, 233, 235)>, <rect(487, 39, 70, 70)>]\n"
     ]
    }
   ],
   "source": [
    "from FromNewToOld import Keywords,WallRects,FurnitureRects\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8gTgWJgGj7p2"
   },
   "source": [
    "# 1. OpenAI Gym For A Custom Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Uh3jG0Rkj7p3"
   },
   "outputs": [],
   "source": [
    "from Room import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8ZxpAR8Rj7p5"
   },
   "outputs": [],
   "source": [
    "env = RoomEnv(Keywords,WallRects,FurnitureRects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhTt3XNij7p8"
   },
   "source": [
    "# 2. Create a Deep Learning Model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RvSScRXcj7p9"
   },
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import *\n",
    "from rl.memory import SequentialMemory\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yFV4_QWSj7p-"
   },
   "outputs": [],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0XBuhvzj7p-",
    "outputId": "92f6224b-197a-4974-85eb-e5ff75c52a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "4\n",
      "(array([507, 157]), 414, False, {})\n",
      "(array([508, 157]), 413, False, {})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(states)\n",
    "print(actions)\n",
    "print(env.step(0))\n",
    "print(env.step(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QPXP6OWAj7p-"
   },
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=states))\n",
    "    model.add(Dense(128, activation='relu', input_shape=states))\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_zw97GX7j7p_"
   },
   "outputs": [],
   "source": [
    "# del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6Tpf6H_0j7p_"
   },
   "outputs": [],
   "source": [
    "model = build_model(states, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dtVi0tOXj7p_",
    "outputId": "cc281261-3c8c-47d5-fa0c-adf260b96441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 17,412\n",
      "Trainable params: 17,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(None, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "pt_depth = model.layers[0].get_input_shape_at(node_index=0)\n",
    "print(pt_depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XKacIXej7qA"
   },
   "source": [
    "# 3. Build Agent with Keras-RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "U8kDaoVIj7qA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[508 157]\n"
     ]
    }
   ],
   "source": [
    "print(env.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RsfBpb9ej7qA"
   },
   "outputs": [],
   "source": [
    "def build_agent(model, actions, policy):\n",
    "    policy = policy\n",
    "    memory = SequentialMemory(limit=30000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                   nb_actions=actions, nb_steps_warmup=500, target_model_update=1e-3)\n",
    "    return dqn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitall( env,keywords):\n",
    "    for i in keywords:\n",
    "        dqn = build_agent(model, actions, EpsGreedyQPolicy(eps=0.2))\n",
    "        dqn.compile(Adam(lr=1e-2), metrics=['mae'])\n",
    "        dqn.fit(env, nb_steps=10000, visualize=True, verbose=1)\n",
    "        env.nextPlease()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "sYl8cAgfj7qB",
    "outputId": "d5dba474-786d-4a66-9e01-2aacb71e595d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From f:\\Programs\\anaconda3\\envs\\reinforcmentlearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      " 1231/10000 [==>...........................] - ETA: 57s - reward: 406.8075"
     ]
    }
   ],
   "source": [
    "\n",
    "# dqn = build_agent(model, actions, EpsGreedyQPolicy(eps=0.2))\n",
    "# dqn.compile(Adam(lr=1e-2), metrics=['mae'])\n",
    "# dqn.fit(env, nb_steps=3000, visualize=True, verbose=1)\n",
    "\n",
    "fitall(env,FurnitureRects)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # dqn = build_agent(model, actions, EpsGreedyQPolicy(eps=0.2))\n",
    "# # dqn.compile(Adam(lr=1e-2), metrics=['mae'])\n",
    "# # dqn.fit(env, nb_steps=3000, visualize=True, verbose=1)\n",
    "\n",
    "# fitall(env,Room2.furniture.keywords)\n",
    "# env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model2 = build_model(states, actions)\n",
    "# dqn2 = build_agent(model2, actions, EpsGreedyQPolicy(eps=0.1))\n",
    "# dqn2.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "# dqn2.fit(env, nb_steps=30000, visualize=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = build_model(states, actions)\n",
    "# env.nextPlease()\n",
    "# dqn3 = build_agent(model2, actions, EpsGreedyQPolicy(eps=0.1))\n",
    "# dqn3.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "# dqn3.fit(env, nb_steps=300, visualize=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = build_model(states, actions)\n",
    "# env.nextPlease()\n",
    "# dqn4 = build_agent(model2, actions, EpsGreedyQPolicy(eps=0.7))\n",
    "# dqn4.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "# dqn4.fit(env, nb_steps=20000, visualize=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.nextPlease()\n",
    "# env.move_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = build_model(states, actions)\n",
    "# dqn5 = build_agent(model3, actions, EpsGreedyQPolicy(eps=0.1))\n",
    "# dqn5.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "# dqn5.fit(env, nb_steps=30, visualize=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tteRF-rBj7qE"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H%M%S\")\n",
    "dqn.save_weights('lastSaved2', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dqb0nLAsj7qB",
    "outputId": "a9b643a5-2357-463e-a9c4-0ce1e261eecf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# scores = dqn.test(env, nb_episodes=5, visualize=True)\n",
    "# env.close()\n",
    "# print(scores.history['episode_reward'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "id": "u3Y3hSwHHibv",
    "outputId": "85f35a85-be28-49b8-fcd5-175b5796aa23"
   },
   "outputs": [],
   "source": [
    "print(env.colided)\n",
    "env.step(0)\n",
    "print(env.colided)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8OzdBNwj7qF"
   },
   "outputs": [],
   "source": [
    "dqn.load_weights('sequential_1doorWindowRandomStartSuccessdqn_weights2.h5f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dqb0nLAsj7qB",
    "outputId": "a9b643a5-2357-463e-a9c4-0ce1e261eecf"
   },
   "outputs": [],
   "source": [
    "scores = dqn.test(env, nb_episodes=5, visualize=True)\n",
    "env.close()\n",
    "print(scores.history['episode_reward'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d8uez7dj7qD"
   },
   "source": [
    "# 4. Reloading Agent from Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZH4dqugBj7qE"
   },
   "outputs": [],
   "source": [
    "del model\n",
    "del dqn\n",
    "del env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fz7RAJ9Rj7qE"
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "actions = env.action_space.n\n",
    "states = env.observation_space.shape[0]\n",
    "model = build_model(states, actions)\n",
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GIM5k-M2j7qF"
   },
   "outputs": [],
   "source": [
    "_ = dqn.test(env, nb_episodes=5, visualize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssrGKaxzj7qG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "reinforcmentlearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b16aa9c2f9ca519bd84c3170bdda05fa03e46a681e2095a6220d679a6ba17b2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
